"""
ğŸ“Š MONITORING DU SCRAPING EN COURS
Script pour suivre l'avancement du scraping complet
"""

import os
import time
import pandas as pd
from datetime import datetime

def monitor_scraping():
    """
    Surveille l'avancement du scraping
    """
    print("ğŸ“Š MONITORING DU SCRAPING EN COURS")
    print("=" * 50)
    
    # RÃ©pertoire des donnÃ©es
    data_dir = "data"
    
    # Chercher les fichiers de scraping rÃ©cents
    if not os.path.exists(data_dir):
        print("âŒ RÃ©pertoire data non trouvÃ©")
        return
    
    files = os.listdir(data_dir)
    scraping_files = [f for f in files if f.startswith("bde_scraping_all_pages_")]
    
    if not scraping_files:
        print("âŒ Aucun fichier de scraping en cours trouvÃ©")
        return
    
    # Prendre le fichier le plus rÃ©cent
    latest_file = max(scraping_files, key=lambda f: os.path.getctime(os.path.join(data_dir, f)))
    filepath = os.path.join(data_dir, latest_file)
    
    print(f"ğŸ“ Fichier surveillÃ© : {latest_file}")
    print(f"ğŸ• DÃ©marrage du monitoring Ã  {datetime.now().strftime('%H:%M:%S')}")
    
    previous_count = 0
    monitoring_start = time.time()
    
    while True:
        try:
            # Lire le fichier CSV actuel
            if os.path.exists(filepath):
                df = pd.read_csv(filepath)
                current_count = len(df)
                
                if current_count != previous_count:
                    elapsed = time.time() - monitoring_start
                    rate = current_count / elapsed * 60 if elapsed > 0 else 0
                    
                    print(f"\nğŸ“Š {datetime.now().strftime('%H:%M:%S')} - Mise Ã  jour !")
                    print(f"   ğŸ¯ BDE scrapÃ©s : {current_count}")
                    print(f"   â±ï¸  DurÃ©e : {elapsed/60:.1f} minutes")
                    print(f"   ğŸ“ˆ Vitesse : {rate:.1f} BDE/minute")
                    
                    # Estimation du temps restant
                    if rate > 0:
                        estimated_total = 30 * 31  # 30 pages Ã— ~31 BDE par page
                        remaining = max(0, estimated_total - current_count)
                        eta_minutes = remaining / rate if rate > 0 else 0
                        print(f"   â³ ETA : {eta_minutes:.1f} minutes restantes")
                        print(f"   ğŸ¯ Progression : {current_count/estimated_total*100:.1f}%")
                    
                    previous_count = current_count
                
                # VÃ©rifier si le fichier a Ã©tÃ© modifiÃ© rÃ©cemment
                last_modified = os.path.getmtime(filepath)
                time_since_modified = time.time() - last_modified
                
                if time_since_modified > 300:  # 5 minutes sans modification
                    print(f"\nâš ï¸  Fichier non modifiÃ© depuis {time_since_modified/60:.1f} minutes")
                    print("   Le scraping pourrait Ãªtre terminÃ© ou bloquÃ©")
                    break
            
            else:
                print("âŒ Fichier non trouvÃ©")
                break
            
            # Attendre avant la prochaine vÃ©rification
            time.sleep(30)  # VÃ©rifier toutes les 30 secondes
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ Monitoring arrÃªtÃ© par l'utilisateur")
            break
        except Exception as e:
            print(f"\nâŒ Erreur : {str(e)}")
            time.sleep(30)
    
    # RÃ©sumÃ© final
    try:
        if os.path.exists(filepath):
            df = pd.read_csv(filepath)
            total_elapsed = time.time() - monitoring_start
            
            print(f"\nğŸ RÃ‰SUMÃ‰ FINAL")
            print(f"   ğŸ“Š Total BDE scrapÃ©s : {len(df)}")
            print(f"   â±ï¸  DurÃ©e totale : {total_elapsed/60:.1f} minutes")
            print(f"   ğŸ“ˆ Vitesse moyenne : {len(df)/(total_elapsed/60):.1f} BDE/minute")
            
            # Statistiques des donnÃ©es
            if len(df) > 0:
                emails_count = df['email'].notna().sum()
                sites_count = df['site_internet'].notna().sum()
                
                print(f"   ğŸ“§ Emails rÃ©cupÃ©rÃ©s : {emails_count} ({emails_count/len(df)*100:.1f}%)")
                print(f"   ğŸŒ Sites web rÃ©cupÃ©rÃ©s : {sites_count} ({sites_count/len(df)*100:.1f}%)")
    except:
        pass

if __name__ == "__main__":
    monitor_scraping() 